{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "    Identify products at risk of backorder before the event occurs so that business has time to react."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Backorder?\n",
    "Backorders are products that are temporarily out of stock, but a customer is permitted to place an order against future inventory. A backorder generally indicates that customer demand for a product or service exceeds a companyâ€™s capacity to supply it. Back orders are both good and bad. Strong demand can drive back orders, but so can suboptimal planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Data file contains the historical data for the 8 weeks prior to the week we are trying to predict. The data was taken as weekly snapshots at the start of each week. Columns are defined as follows:\n",
    "\n",
    "    sku - Random ID for the product\n",
    "\n",
    "    national_inv - Current inventory level for the part\n",
    "\n",
    "    lead_time - Transit time for product (if available)\n",
    "\n",
    "    in_transit_qty - Amount of product in transit from source\n",
    "\n",
    "    forecast_3_month - Forecast sales for the next 3 months\n",
    "\n",
    "    forecast_6_month - Forecast sales for the next 6 months\n",
    "\n",
    "    forecast_9_month - Forecast sales for the next 9 months\n",
    "\n",
    "    sales_1_month - Sales quantity for the prior 1 month time period\n",
    "\n",
    "    sales_3_month - Sales quantity for the prior 3 month time period\n",
    "\n",
    "    sales_6_month - Sales quantity for the prior 6 month time period\n",
    "\n",
    "    sales_9_month - Sales quantity for the prior 9 month time period\n",
    "\n",
    "    min_bank - Minimum recommend amount to stock\n",
    "\n",
    "    potential_issue - Source issue for part identified\n",
    "\n",
    "    pieces_past_due - Parts overdue from source\n",
    "\n",
    "    perf_6_month_avg - Source performance for prior 6 month period\n",
    "\n",
    "    perf_12_month_avg - Source performance for prior 12 month period\n",
    "\n",
    "    local_bo_qty - Amount of stock orders overdue\n",
    "\n",
    "    deck_risk - Part risk flag\n",
    "\n",
    "    oe_constraint - Part risk flag\n",
    "\n",
    "    ppap_risk - Part risk flag\n",
    "\n",
    "    stop_auto_buy - Part risk flag\n",
    "\n",
    "    rev_stop - Part risk flag\n",
    "\n",
    "    went_on_backorder - Product actually went on backorder. This is the target value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "#### Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seemabasantani/Documents/Academics/Batch 56/CSE7321c/ANN/Lab/20181215_Batch47_CSE7321c_Lab02_ANN/20181215_Batch47_CSE7321c_Lab02'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For setting working directory, if required\n",
    "#os.chdir('path to file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"BackOrders.csv\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the number row and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61589, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'national_inv', 'lead_time', 'in_transit_qty',\n",
       "       'forecast_3_month', 'forecast_6_month', 'forecast_9_month',\n",
       "       'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month',\n",
       "       'min_bank', 'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
       "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
       "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=61589, step=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the top rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1888279</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1870557</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1475481</td>\n",
       "      <td>258</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>132</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1888279           117        NaN               0                 0   \n",
       "1  1870557             7        2.0               0                 0   \n",
       "2  1475481           258       15.0              10                10   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0                 0                 0              0              0   \n",
       "1                 0                 0              0              0   \n",
       "2                77               184             46            132   \n",
       "\n",
       "   sales_6_month        ...         pieces_past_due  perf_6_month_avg  \\\n",
       "0             15        ...                       0            -99.00   \n",
       "1              0        ...                       0              0.50   \n",
       "2            256        ...                       0              0.54   \n",
       "\n",
       "  perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
       "0            -99.00             0         No             No        Yes   \n",
       "1              0.28             0        Yes             No         No   \n",
       "2              0.70             0         No             No         No   \n",
       "\n",
       "  stop_auto_buy rev_stop went_on_backorder  \n",
       "0           Yes       No                No  \n",
       "1           Yes       No                No  \n",
       "2           Yes       No                No  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows a quick statistic summary of your data using describe.\n",
    "\n",
    "For object data (e.g. strings or timestamps), the resultâ€™s index will include count, unique, top, and freq. \n",
    "\n",
    "The top is the most common value.\n",
    "\n",
    "The freq is the most common valueâ€™s frequency.\n",
    "\n",
    "Timestamps also include the first and last items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>58186.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>6.158900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589.000000</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "      <td>61589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48145</td>\n",
       "      <td>61577</td>\n",
       "      <td>53792</td>\n",
       "      <td>59303</td>\n",
       "      <td>61569</td>\n",
       "      <td>50296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.037188e+06</td>\n",
       "      <td>287.721882</td>\n",
       "      <td>7.559619</td>\n",
       "      <td>30.192843</td>\n",
       "      <td>1.692728e+02</td>\n",
       "      <td>3.150413e+02</td>\n",
       "      <td>4.535760e+02</td>\n",
       "      <td>44.742957</td>\n",
       "      <td>150.732631</td>\n",
       "      <td>2.835465e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>-6.264182</td>\n",
       "      <td>-5.863664</td>\n",
       "      <td>1.205361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.564178e+05</td>\n",
       "      <td>4233.906931</td>\n",
       "      <td>6.498952</td>\n",
       "      <td>792.869253</td>\n",
       "      <td>5.286742e+03</td>\n",
       "      <td>9.774362e+03</td>\n",
       "      <td>1.420201e+04</td>\n",
       "      <td>1373.805831</td>\n",
       "      <td>5224.959649</td>\n",
       "      <td>8.872270e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>42.309229</td>\n",
       "      <td>25.537906</td>\n",
       "      <td>24.844514</td>\n",
       "      <td>29.981155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.068628e+06</td>\n",
       "      <td>-2999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.498574e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.898033e+06</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.314826e+06</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.284895e+06</td>\n",
       "      <td>673445.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>170976.000000</td>\n",
       "      <td>1.126656e+06</td>\n",
       "      <td>2.094336e+06</td>\n",
       "      <td>3.062016e+06</td>\n",
       "      <td>295197.000000</td>\n",
       "      <td>934593.000000</td>\n",
       "      <td>1.799099e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7392.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sku   national_inv     lead_time  in_transit_qty  \\\n",
       "count   6.158900e+04   61589.000000  58186.000000    61589.000000   \n",
       "unique           NaN            NaN           NaN             NaN   \n",
       "top              NaN            NaN           NaN             NaN   \n",
       "freq             NaN            NaN           NaN             NaN   \n",
       "mean    2.037188e+06     287.721882      7.559619       30.192843   \n",
       "std     6.564178e+05    4233.906931      6.498952      792.869253   \n",
       "min     1.068628e+06   -2999.000000      0.000000        0.000000   \n",
       "25%     1.498574e+06       3.000000      4.000000        0.000000   \n",
       "50%     1.898033e+06      10.000000      8.000000        0.000000   \n",
       "75%     2.314826e+06      57.000000      8.000000        0.000000   \n",
       "max     3.284895e+06  673445.000000     52.000000   170976.000000   \n",
       "\n",
       "        forecast_3_month  forecast_6_month  forecast_9_month  sales_1_month  \\\n",
       "count       6.158900e+04      6.158900e+04      6.158900e+04   61589.000000   \n",
       "unique               NaN               NaN               NaN            NaN   \n",
       "top                  NaN               NaN               NaN            NaN   \n",
       "freq                 NaN               NaN               NaN            NaN   \n",
       "mean        1.692728e+02      3.150413e+02      4.535760e+02      44.742957   \n",
       "std         5.286742e+03      9.774362e+03      1.420201e+04    1373.805831   \n",
       "min         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "25%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "50%         0.000000e+00      0.000000e+00      0.000000e+00       0.000000   \n",
       "75%         1.200000e+01      2.500000e+01      3.600000e+01       6.000000   \n",
       "max         1.126656e+06      2.094336e+06      3.062016e+06  295197.000000   \n",
       "\n",
       "        sales_3_month  sales_6_month        ...         pieces_past_due  \\\n",
       "count    61589.000000   6.158900e+04        ...            61589.000000   \n",
       "unique            NaN            NaN        ...                     NaN   \n",
       "top               NaN            NaN        ...                     NaN   \n",
       "freq              NaN            NaN        ...                     NaN   \n",
       "mean       150.732631   2.835465e+02        ...                1.605400   \n",
       "std       5224.959649   8.872270e+03        ...               42.309229   \n",
       "min          0.000000   0.000000e+00        ...                0.000000   \n",
       "25%          0.000000   0.000000e+00        ...                0.000000   \n",
       "50%          2.000000   4.000000e+00        ...                0.000000   \n",
       "75%         17.000000   3.400000e+01        ...                0.000000   \n",
       "max     934593.000000   1.799099e+06        ...             7392.000000   \n",
       "\n",
       "        perf_6_month_avg perf_12_month_avg  local_bo_qty  deck_risk  \\\n",
       "count       61589.000000      61589.000000  61589.000000      61589   \n",
       "unique               NaN               NaN           NaN          2   \n",
       "top                  NaN               NaN           NaN         No   \n",
       "freq                 NaN               NaN           NaN      48145   \n",
       "mean           -6.264182         -5.863664      1.205361        NaN   \n",
       "std            25.537906         24.844514     29.981155        NaN   \n",
       "min           -99.000000        -99.000000      0.000000        NaN   \n",
       "25%             0.620000          0.640000      0.000000        NaN   \n",
       "50%             0.820000          0.800000      0.000000        NaN   \n",
       "75%             0.960000          0.950000      0.000000        NaN   \n",
       "max             1.000000          1.000000   2999.000000        NaN   \n",
       "\n",
       "        oe_constraint  ppap_risk stop_auto_buy rev_stop went_on_backorder  \n",
       "count           61589      61589         61589    61589             61589  \n",
       "unique              2          2             2        2                 2  \n",
       "top                No         No           Yes       No                No  \n",
       "freq            61577      53792         59303    61569             50296  \n",
       "mean              NaN        NaN           NaN      NaN               NaN  \n",
       "std               NaN        NaN           NaN      NaN               NaN  \n",
       "min               NaN        NaN           NaN      NaN               NaN  \n",
       "25%               NaN        NaN           NaN      NaN               NaN  \n",
       "50%               NaN        NaN           NaN      NaN               NaN  \n",
       "75%               NaN        NaN           NaN      NaN               NaN  \n",
       "max               NaN        NaN           NaN      NaN               NaN  \n",
       "\n",
       "[11 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                    int64\n",
       "national_inv           int64\n",
       "lead_time            float64\n",
       "in_transit_qty         int64\n",
       "forecast_3_month       int64\n",
       "forecast_6_month       int64\n",
       "forecast_9_month       int64\n",
       "sales_1_month          int64\n",
       "sales_3_month          int64\n",
       "sales_6_month          int64\n",
       "sales_9_month          int64\n",
       "min_bank               int64\n",
       "potential_issue       object\n",
       "pieces_past_due        int64\n",
       "perf_6_month_avg     float64\n",
       "perf_12_month_avg    float64\n",
       "local_bo_qty           int64\n",
       "deck_risk             object\n",
       "oe_constraint         object\n",
       "ppap_risk             object\n",
       "stop_auto_buy         object\n",
       "rev_stop              object\n",
       "went_on_backorder     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "sku is Categorical but is interpreted as int64 \n",
    "potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder are also \n",
    "categorical but is interpreted as object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all the attributes to appropriate type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type conversion\n",
    "\n",
    "    Using astype('category') to convert potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, and went_on_backorder attributes to categorical attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sku', 'potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']:\n",
    "    data[col] = data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data type of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                  category\n",
       "national_inv            int64\n",
       "lead_time             float64\n",
       "in_transit_qty          int64\n",
       "forecast_3_month        int64\n",
       "forecast_6_month        int64\n",
       "forecast_9_month        int64\n",
       "sales_1_month           int64\n",
       "sales_3_month           int64\n",
       "sales_6_month           int64\n",
       "sales_9_month           int64\n",
       "min_bank                int64\n",
       "potential_issue      category\n",
       "pieces_past_due         int64\n",
       "perf_6_month_avg      float64\n",
       "perf_12_month_avg     float64\n",
       "local_bo_qty            int64\n",
       "deck_risk            category\n",
       "oe_constraint        category\n",
       "ppap_risk            category\n",
       "stop_auto_buy        category\n",
       "rev_stop             category\n",
       "went_on_backorder    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete sku attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61589"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(np.unique(data.sku))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('sku', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data\n",
    "\n",
    "Missing value analysis and dropping the records with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv            0\n",
       "lead_time            3403\n",
       "in_transit_qty          0\n",
       "forecast_3_month        0\n",
       "forecast_6_month        0\n",
       "forecast_9_month        0\n",
       "sales_1_month           0\n",
       "sales_3_month           0\n",
       "sales_6_month           0\n",
       "sales_9_month           0\n",
       "min_bank                0\n",
       "potential_issue         0\n",
       "pieces_past_due         0\n",
       "perf_6_month_avg        0\n",
       "perf_12_month_avg       0\n",
       "local_bo_qty            0\n",
       "deck_risk               0\n",
       "oe_constraint           0\n",
       "ppap_risk               0\n",
       "stop_auto_buy           0\n",
       "rev_stop                0\n",
       "went_on_backorder       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the number of records before and after missing value records removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61589, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the number of missing values is about 5%. For initial analysis we ignore all these records\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national_inv         0\n",
      "lead_time            0\n",
      "in_transit_qty       0\n",
      "forecast_3_month     0\n",
      "forecast_6_month     0\n",
      "forecast_9_month     0\n",
      "sales_1_month        0\n",
      "sales_3_month        0\n",
      "sales_6_month        0\n",
      "sales_9_month        0\n",
      "min_bank             0\n",
      "potential_issue      0\n",
      "pieces_past_due      0\n",
      "perf_6_month_avg     0\n",
      "perf_12_month_avg    0\n",
      "local_bo_qty         0\n",
      "deck_risk            0\n",
      "oe_constraint        0\n",
      "ppap_risk            0\n",
      "stop_auto_buy        0\n",
      "rev_stop             0\n",
      "went_on_backorder    0\n",
      "dtype: int64\n",
      "----------------------------------\n",
      "(58186, 22)\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "print(\"----------------------------------\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical to Numeric\n",
    "\n",
    "For some of the models all the independent attribute should be of type numeric and ANN model is one among them.\n",
    "But this data set has some categorial attributes.\n",
    "\n",
    "'pandas.get_dummies' To convert convert categorical variable into dummy/indicator variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
      "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
      "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating dummy variables.\n",
    "\n",
    "If we have k levels in a category, then we create k-1 dummy variables as the last one would be redundant. So we use the parameter drop_first in pd.get_dummies function that drops the first level in each of the category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_Attributes = data.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(columns=categorical_Attributes, data=data, prefix=categorical_Attributes, prefix_sep=\"_\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'pieces_past_due', 'perf_6_month_avg', 'perf_12_month_avg',\n",
      "       'local_bo_qty', 'potential_issue_Yes', 'deck_risk_Yes',\n",
      "       'oe_constraint_Yes', 'ppap_risk_Yes', 'stop_auto_buy_Yes',\n",
      "       'rev_stop_Yes', 'went_on_backorder_Yes'],\n",
      "      dtype='object') (58186, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data.columns, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target attribute distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    47217\n",
       "1    10969\n",
       "Name: went_on_backorder_Yes, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['went_on_backorder_Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split\n",
    "\n",
    "Using sklearn.model_selection.train_test_split\n",
    "\n",
    "    Split arrays or matrices into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing train test split on the data\n",
    "X, y = data.loc[:,data.columns!='went_on_backorder_Yes'].values, data.loc[:,'went_on_backorder_Yes'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify = data['went_on_backorder_Yes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    33052\n",
      "1     7678\n",
      "dtype: int64\n",
      "0    14165\n",
      "1     3291\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To get the distribution in the target in train and test\n",
    "print(pd.value_counts(y_train))\n",
    "print(pd.value_counts(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building a logistic regression model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=123, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on train data\n",
    "train_pred = classifier.predict(X_train)\n",
    "# Predictions on test data\n",
    "test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Train Data: \n",
      " [[32926   126]\n",
      " [ 7036   642]]\n",
      "Confusion Matrix - Test Data: \n",
      " [[14112    53]\n",
      " [ 3015   276]]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "print(\"Confusion Matrix - Train Data: \\n\", confusion_matrix_train)\n",
    "# Test data\n",
    "confusion_matrix_test= confusion_matrix(y_test, test_pred)\n",
    "print(\"Confusion Matrix - Test Data: \\n\", confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Specificity:  0.9961878252450683\n",
      "Train Recall:  0.08361552487626986\n",
      "Train Precision:  0.8359375\n",
      "Train Accuracy:  0.8241590964890744\n"
     ]
    }
   ],
   "source": [
    "# Metrics on train data for logistic regression model\n",
    "#Accuracy\n",
    "accuracy_Train_logReg = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_logReg = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_logReg = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_logReg = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train Specificity: \",specificity_Train_logReg)\n",
    "print(\"Train Recall: \",recall_Train_logReg)\n",
    "print(\"Train Precision: \",precision_Train_logReg)\n",
    "print(\"Train Accuracy: \",accuracy_Train_logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Specificity:  0.9962583833392163\n",
      "Test Recall:  0.08386508659981769\n",
      "Test Precision:  0.8389057750759878\n",
      "Test Accuracy:  0.824243813015582\n"
     ]
    }
   ],
   "source": [
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_logReg = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_logReg = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_logReg = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_logReg = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test Specificity: \",specificity_Test_logReg)\n",
    "print(\"Test Recall: \",recall_Test_logReg)\n",
    "print(\"Test Precision: \",precision_Test_logReg)\n",
    "print(\"Test Accuracy: \",accuracy_Test_logReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fc_dense_layers_keras.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. \n",
    "\n",
    "* The keras sequential api enables us to build common yet complex neural network architectures flexibly\n",
    "\n",
    "* Objects of the Keras sequential class, can have multiple neural network layers stacked on top of one another\n",
    "\n",
    "![](img/keras_sequential_api.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=64, input_dim=21, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Compilation\n",
    "Before training a model, you need to configure the learning process, which is done via the compile method. receives three arguments\n",
    "\n",
    "* optimizer - An optimizer. An optimizer is an algorithm that uses this feedback signal, to actually update the weights so that the output from the network gets closer to the ground truth.\n",
    "* loss - A loss function. This is the objective function that the model will try to minimize.\n",
    "* metrics - A list of error metrics. This is for users reference and does not add value to the weights calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C. Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the  fit function\n",
    "\n",
    "* epoch = one forward pass and one backward pass of all the training examples\n",
    "* batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40730/40730 [==============================] - 2s 38us/step - loss: 0.3492 - acc: 0.8408\n",
      "Epoch 2/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2844 - acc: 0.8761\n",
      "Epoch 3/100\n",
      "40730/40730 [==============================] - 1s 29us/step - loss: 0.2681 - acc: 0.8865\n",
      "Epoch 4/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2648 - acc: 0.8887\n",
      "Epoch 5/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2594 - acc: 0.8911\n",
      "Epoch 6/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2584 - acc: 0.8927\n",
      "Epoch 7/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2585 - acc: 0.8924\n",
      "Epoch 8/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2556 - acc: 0.8929\n",
      "Epoch 9/100\n",
      "40730/40730 [==============================] - 1s 19us/step - loss: 0.2560 - acc: 0.8937\n",
      "Epoch 10/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2541 - acc: 0.8952\n",
      "Epoch 11/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2545 - acc: 0.8947\n",
      "Epoch 12/100\n",
      "40730/40730 [==============================] - 1s 28us/step - loss: 0.2516 - acc: 0.8953\n",
      "Epoch 13/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2498 - acc: 0.8960\n",
      "Epoch 14/100\n",
      "40730/40730 [==============================] - 1s 29us/step - loss: 0.2473 - acc: 0.8967\n",
      "Epoch 15/100\n",
      "40730/40730 [==============================] - 1s 28us/step - loss: 0.2473 - acc: 0.8982\n",
      "Epoch 16/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2477 - acc: 0.8960\n",
      "Epoch 17/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2508 - acc: 0.8955\n",
      "Epoch 18/100\n",
      "40730/40730 [==============================] - 1s 29us/step - loss: 0.2463 - acc: 0.8976: 0s - loss: 0.2480 - acc: \n",
      "Epoch 19/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2490 - acc: 0.8979\n",
      "Epoch 20/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2499 - acc: 0.8961\n",
      "Epoch 21/100\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.2473 - acc: 0.8979\n",
      "Epoch 22/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2441 - acc: 0.8987\n",
      "Epoch 23/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2449 - acc: 0.8984\n",
      "Epoch 24/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2476 - acc: 0.8978\n",
      "Epoch 25/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2527 - acc: 0.8945\n",
      "Epoch 26/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2550 - acc: 0.8945\n",
      "Epoch 27/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2513 - acc: 0.8970\n",
      "Epoch 28/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2602 - acc: 0.8930: 0s - loss: 0.2613 - \n",
      "Epoch 29/100\n",
      "40730/40730 [==============================] - 1s 29us/step - loss: 0.2520 - acc: 0.8962\n",
      "Epoch 30/100\n",
      "40730/40730 [==============================] - 2s 41us/step - loss: 0.2512 - acc: 0.8957\n",
      "Epoch 31/100\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.2547 - acc: 0.8940\n",
      "Epoch 32/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2546 - acc: 0.8937\n",
      "Epoch 33/100\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.2560 - acc: 0.8936\n",
      "Epoch 34/100\n",
      "40730/40730 [==============================] - 1s 30us/step - loss: 0.2510 - acc: 0.8963: 0s - loss: 0.2435 - a - ETA: 0s - loss: 0.2511 - acc\n",
      "Epoch 35/100\n",
      "40730/40730 [==============================] - 1s 27us/step - loss: 0.2521 - acc: 0.8958\n",
      "Epoch 36/100\n",
      "40730/40730 [==============================] - 1s 31us/step - loss: 0.2581 - acc: 0.8917\n",
      "Epoch 37/100\n",
      "40730/40730 [==============================] - 1s 30us/step - loss: 0.2505 - acc: 0.8959\n",
      "Epoch 38/100\n",
      "40730/40730 [==============================] - 1s 32us/step - loss: 0.2500 - acc: 0.8958\n",
      "Epoch 39/100\n",
      "40730/40730 [==============================] - 1s 27us/step - loss: 0.2545 - acc: 0.8931\n",
      "Epoch 40/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2525 - acc: 0.8944: 0s - loss: 0.2529 - acc: 0\n",
      "Epoch 41/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2477 - acc: 0.8969\n",
      "Epoch 42/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2458 - acc: 0.8970\n",
      "Epoch 43/100\n",
      "40730/40730 [==============================] - 1s 30us/step - loss: 0.2454 - acc: 0.8981\n",
      "Epoch 44/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2505 - acc: 0.8987\n",
      "Epoch 45/100\n",
      "40730/40730 [==============================] - 1s 27us/step - loss: 0.2562 - acc: 0.8938\n",
      "Epoch 46/100\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.2510 - acc: 0.8963\n",
      "Epoch 47/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2517 - acc: 0.8950\n",
      "Epoch 48/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2597 - acc: 0.8894: 0s - loss: 0.25\n",
      "Epoch 49/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2534 - acc: 0.8944: 0s - loss: 0.2548 - acc:\n",
      "Epoch 50/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2535 - acc: 0.8940\n",
      "Epoch 51/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2508 - acc: 0.8950\n",
      "Epoch 52/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2530 - acc: 0.8959\n",
      "Epoch 53/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2544 - acc: 0.8952\n",
      "Epoch 54/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2681 - acc: 0.8883\n",
      "Epoch 55/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2563 - acc: 0.8954\n",
      "Epoch 56/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2537 - acc: 0.8964: 0s - loss: 0.2\n",
      "Epoch 57/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2526 - acc: 0.8967\n",
      "Epoch 58/100\n",
      "40730/40730 [==============================] - 1s 28us/step - loss: 0.2556 - acc: 0.8928\n",
      "Epoch 59/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2598 - acc: 0.8936\n",
      "Epoch 60/100\n",
      "40730/40730 [==============================] - 1s 27us/step - loss: 0.2598 - acc: 0.8907\n",
      "Epoch 61/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2508 - acc: 0.8947: 0s - loss: 0.2537 - \n",
      "Epoch 62/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2548 - acc: 0.8934\n",
      "Epoch 63/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2526 - acc: 0.8946\n",
      "Epoch 64/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2539 - acc: 0.8951\n",
      "Epoch 65/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2518 - acc: 0.8973\n",
      "Epoch 66/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2501 - acc: 0.8976\n",
      "Epoch 67/100\n",
      "40730/40730 [==============================] - 1s 27us/step - loss: 0.2476 - acc: 0.8986\n",
      "Epoch 68/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2513 - acc: 0.8975\n",
      "Epoch 69/100\n",
      "40730/40730 [==============================] - 1s 27us/step - loss: 0.2513 - acc: 0.8965\n",
      "Epoch 70/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2495 - acc: 0.8968\n",
      "Epoch 71/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2507 - acc: 0.8969\n",
      "Epoch 72/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2505 - acc: 0.8974\n",
      "Epoch 73/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2502 - acc: 0.8962\n",
      "Epoch 74/100\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.2569 - acc: 0.8923\n",
      "Epoch 75/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2466 - acc: 0.8999\n",
      "Epoch 76/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2500 - acc: 0.8972\n",
      "Epoch 77/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2468 - acc: 0.8998: 0s - loss: 0.2449\n",
      "Epoch 78/100\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.2533 - acc: 0.8982\n",
      "Epoch 79/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2510 - acc: 0.8983\n",
      "Epoch 80/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2546 - acc: 0.8940\n",
      "Epoch 81/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2549 - acc: 0.8948\n",
      "Epoch 82/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2534 - acc: 0.8972\n",
      "Epoch 83/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2571 - acc: 0.8950\n",
      "Epoch 84/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2527 - acc: 0.8954\n",
      "Epoch 85/100\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.2514 - acc: 0.8936: 0s - loss: 0.2493 - \n",
      "Epoch 86/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2556 - acc: 0.8935\n",
      "Epoch 87/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2495 - acc: 0.8963\n",
      "Epoch 88/100\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.2487 - acc: 0.8947\n",
      "Epoch 89/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2501 - acc: 0.8963\n",
      "Epoch 90/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2453 - acc: 0.8989\n",
      "Epoch 91/100\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.2446 - acc: 0.8984\n",
      "Epoch 92/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2441 - acc: 0.8991\n",
      "Epoch 93/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2479 - acc: 0.8964\n",
      "Epoch 94/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2551 - acc: 0.8944\n",
      "Epoch 95/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2516 - acc: 0.8951\n",
      "Epoch 96/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2563 - acc: 0.8962\n",
      "Epoch 97/100\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.2553 - acc: 0.8960\n",
      "Epoch 98/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2606 - acc: 0.8928\n",
      "Epoch 99/100\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.2516 - acc: 0.8965: 0s - loss: 0.2526 - acc: \n",
      "Epoch 100/100\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.2526 - acc: 0.8962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a29318978>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE : Don't run the following line of code as we do not yet have X_train and y_train\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Base model (Perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model = Sequential()\n",
    "\n",
    "perceptron_model.add(Dense(1, input_dim=21, activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40730/40730 [==============================] - 1s 28us/step - loss: 0.4759 - acc: 0.8397\n",
      "Epoch 2/30\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.4125 - acc: 0.8490\n",
      "Epoch 3/30\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.4136 - acc: 0.8547\n",
      "Epoch 4/30\n",
      "40730/40730 [==============================] - 1s 34us/step - loss: 0.4044 - acc: 0.8585\n",
      "Epoch 5/30\n",
      "40730/40730 [==============================] - 2s 37us/step - loss: 0.4098 - acc: 0.8602\n",
      "Epoch 6/30\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.5973 - acc: 0.8489\n",
      "Epoch 7/30\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.3935 - acc: 0.8662\n",
      "Epoch 8/30\n",
      "40730/40730 [==============================] - 1s 29us/step - loss: 0.4184 - acc: 0.8599\n",
      "Epoch 9/30\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.3957 - acc: 0.8683\n",
      "Epoch 10/30\n",
      "40730/40730 [==============================] - 1s 29us/step - loss: 0.3941 - acc: 0.8650\n",
      "Epoch 11/30\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.3934 - acc: 0.8649\n",
      "Epoch 12/30\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.3974 - acc: 0.8632\n",
      "Epoch 13/30\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.4138 - acc: 0.8626\n",
      "Epoch 14/30\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.4003 - acc: 0.8652\n",
      "Epoch 15/30\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.4043 - acc: 0.8641\n",
      "Epoch 16/30\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.4087 - acc: 0.8636\n",
      "Epoch 17/30\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.4170 - acc: 0.8662\n",
      "Epoch 18/30\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.4077 - acc: 0.8652\n",
      "Epoch 19/30\n",
      "40730/40730 [==============================] - 1s 26us/step - loss: 0.3964 - acc: 0.8655\n",
      "Epoch 20/30\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.3968 - acc: 0.8642: 0s - loss: 0.3971 - acc: 0.8\n",
      "Epoch 21/30\n",
      "40730/40730 [==============================] - 1s 24us/step - loss: 0.4070 - acc: 0.8639\n",
      "Epoch 22/30\n",
      "40730/40730 [==============================] - 1s 20us/step - loss: 0.4498 - acc: 0.8612\n",
      "Epoch 23/30\n",
      "40730/40730 [==============================] - 1s 22us/step - loss: 0.4005 - acc: 0.8665\n",
      "Epoch 24/30\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.3954 - acc: 0.8655\n",
      "Epoch 25/30\n",
      "40730/40730 [==============================] - 1s 21us/step - loss: 0.4371 - acc: 0.8649\n",
      "Epoch 26/30\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.4180 - acc: 0.8642\n",
      "Epoch 27/30\n",
      "40730/40730 [==============================] - 1s 23us/step - loss: 0.4106 - acc: 0.8671\n",
      "Epoch 28/30\n",
      "40730/40730 [==============================] - 1s 27us/step - loss: 0.4400 - acc: 0.8636\n",
      "Epoch 29/30\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.3932 - acc: 0.8702\n",
      "Epoch 30/30\n",
      "40730/40730 [==============================] - 1s 25us/step - loss: 0.4096 - acc: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10d841908>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model.fit(X_train, y_train, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32569   483]\n",
      " [ 5505  2173]]\n",
      "[[13930   235]\n",
      " [ 2344   947]]\n"
     ]
    }
   ],
   "source": [
    "test_pred=perceptron_model.predict_classes(X_test)\n",
    "train_pred=perceptron_model.predict_classes(X_train)\n",
    "\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Accuracy, True Negative Rate and True Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TNR:  0.9853866634394288\n",
      "Train TPR:  0.28301641052357385\n",
      "Train Accuracy:  0.8529830591701448\n",
      "-----------------------\n",
      "Test TNR:  0.983409812919167\n",
      "Test TPR:  0.28775448192038894\n",
      "Test Accuracy:  0.8522571035747021\n"
     ]
    }
   ],
   "source": [
    "Accuracy_Train=(confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "TNR_Train= confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "TPR_Train= confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train TNR: \",TNR_Train)\n",
    "print(\"Train TPR: \",TPR_Train)\n",
    "print(\"Train Accuracy: \",Accuracy_Train)\n",
    "print(\"-----------------------\")\n",
    "\n",
    "Accuracy_Test=(confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "TNR_Test= confusion_matrix_test[0,0]/(confusion_matrix_test[0,0] +confusion_matrix_test[0,1])\n",
    "TPR_Test= confusion_matrix_test[1,1]/(confusion_matrix_test[1,0] +confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test TNR: \",TNR_Test)\n",
    "print(\"Test TPR: \",TPR_Test)\n",
    "print(\"Test Accuracy: \",Accuracy_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = Sequential()\n",
    "\n",
    "mlp_model.add(Dense(12, input_dim=21, activation='sigmoid', kernel_initializer='normal'))\n",
    "mlp_model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                264       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 277\n",
      "Trainable params: 277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32584 samples, validate on 8146 samples\n",
      "Epoch 1/30\n",
      "32584/32584 [==============================] - 1s 38us/step - loss: 0.4129 - acc: 0.8080 - val_loss: 0.3260 - val_acc: 0.8372\n",
      "Epoch 2/30\n",
      "32584/32584 [==============================] - 1s 30us/step - loss: 0.2939 - acc: 0.8631 - val_loss: 0.2803 - val_acc: 0.8802\n",
      "Epoch 3/30\n",
      "32584/32584 [==============================] - 1s 27us/step - loss: 0.2650 - acc: 0.8898 - val_loss: 0.2625 - val_acc: 0.8943\n",
      "Epoch 4/30\n",
      "32584/32584 [==============================] - 1s 31us/step - loss: 0.2525 - acc: 0.8977 - val_loss: 0.2542 - val_acc: 0.8975\n",
      "Epoch 5/30\n",
      "32584/32584 [==============================] - 1s 31us/step - loss: 0.2467 - acc: 0.8995 - val_loss: 0.2495 - val_acc: 0.8976\n",
      "Epoch 6/30\n",
      "32584/32584 [==============================] - 1s 33us/step - loss: 0.2429 - acc: 0.9019 - val_loss: 0.2464 - val_acc: 0.8981\n",
      "Epoch 7/30\n",
      "32584/32584 [==============================] - 1s 28us/step - loss: 0.2407 - acc: 0.9014 - val_loss: 0.2488 - val_acc: 0.8973\n",
      "Epoch 8/30\n",
      "32584/32584 [==============================] - 1s 28us/step - loss: 0.2387 - acc: 0.9021 - val_loss: 0.2445 - val_acc: 0.9007\n",
      "Epoch 9/30\n",
      "32584/32584 [==============================] - 1s 31us/step - loss: 0.2390 - acc: 0.9015 - val_loss: 0.2415 - val_acc: 0.9022\n",
      "Epoch 10/30\n",
      "32584/32584 [==============================] - 1s 29us/step - loss: 0.2362 - acc: 0.9029 - val_loss: 0.2430 - val_acc: 0.9003\n",
      "Epoch 11/30\n",
      "32584/32584 [==============================] - 1s 33us/step - loss: 0.2356 - acc: 0.9020 - val_loss: 0.2394 - val_acc: 0.9028\n",
      "Epoch 12/30\n",
      "32584/32584 [==============================] - 1s 27us/step - loss: 0.2333 - acc: 0.9037 - val_loss: 0.2380 - val_acc: 0.9018\n",
      "Epoch 13/30\n",
      "32584/32584 [==============================] - 1s 30us/step - loss: 0.2336 - acc: 0.9031 - val_loss: 0.2426 - val_acc: 0.8963\n",
      "Epoch 14/30\n",
      "32584/32584 [==============================] - 1s 36us/step - loss: 0.2337 - acc: 0.9035 - val_loss: 0.2388 - val_acc: 0.9018\n",
      "Epoch 15/30\n",
      "32584/32584 [==============================] - 1s 29us/step - loss: 0.2342 - acc: 0.9019 - val_loss: 0.2384 - val_acc: 0.9015\n",
      "Epoch 16/30\n",
      "32584/32584 [==============================] - 1s 32us/step - loss: 0.2342 - acc: 0.9022 - val_loss: 0.2382 - val_acc: 0.9029\n",
      "Epoch 17/30\n",
      "32584/32584 [==============================] - 1s 29us/step - loss: 0.2335 - acc: 0.9029 - val_loss: 0.2373 - val_acc: 0.9013\n",
      "Epoch 18/30\n",
      "32584/32584 [==============================] - 1s 33us/step - loss: 0.2321 - acc: 0.9041 - val_loss: 0.2366 - val_acc: 0.9024\n",
      "Epoch 19/30\n",
      "32584/32584 [==============================] - 1s 27us/step - loss: 0.2328 - acc: 0.9028 - val_loss: 0.2373 - val_acc: 0.9006\n",
      "Epoch 20/30\n",
      "32584/32584 [==============================] - 1s 28us/step - loss: 0.2311 - acc: 0.9043 - val_loss: 0.2361 - val_acc: 0.9041\n",
      "Epoch 21/30\n",
      "32584/32584 [==============================] - 1s 32us/step - loss: 0.2302 - acc: 0.9047 - val_loss: 0.2352 - val_acc: 0.9013\n",
      "Epoch 22/30\n",
      "32584/32584 [==============================] - 1s 29us/step - loss: 0.2296 - acc: 0.9057 - val_loss: 0.2350 - val_acc: 0.9049\n",
      "Epoch 23/30\n",
      "32584/32584 [==============================] - 1s 31us/step - loss: 0.2298 - acc: 0.9043 - val_loss: 0.2341 - val_acc: 0.9045\n",
      "Epoch 24/30\n",
      "32584/32584 [==============================] - 1s 24us/step - loss: 0.2288 - acc: 0.9054 - val_loss: 0.2335 - val_acc: 0.9062\n",
      "Epoch 25/30\n",
      "32584/32584 [==============================] - 1s 28us/step - loss: 0.2287 - acc: 0.9053 - val_loss: 0.2336 - val_acc: 0.9058\n",
      "Epoch 26/30\n",
      "32584/32584 [==============================] - 1s 24us/step - loss: 0.2293 - acc: 0.9039 - val_loss: 0.2338 - val_acc: 0.9046\n",
      "Epoch 27/30\n",
      "32584/32584 [==============================] - 1s 29us/step - loss: 0.2295 - acc: 0.9053 - val_loss: 0.2308 - val_acc: 0.9061\n",
      "Epoch 28/30\n",
      "32584/32584 [==============================] - 1s 28us/step - loss: 0.2277 - acc: 0.9059 - val_loss: 0.2335 - val_acc: 0.9041\n",
      "Epoch 29/30\n",
      "32584/32584 [==============================] - 1s 31us/step - loss: 0.2273 - acc: 0.9061 - val_loss: 0.2346 - val_acc: 0.9050\n",
      "Epoch 30/30\n",
      "32584/32584 [==============================] - 1s 24us/step - loss: 0.2297 - acc: 0.9052 - val_loss: 0.2370 - val_acc: 0.9044\n"
     ]
    }
   ],
   "source": [
    "#model_history = ann_model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "model_history = mlp_model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = mlp_model.predict_classes(X_train)\n",
    "\n",
    "test_pred = mlp_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting evaluation metrics and evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31257  1795]\n",
      " [ 2082  5596]]\n",
      "[[13328   837]\n",
      " [  928  2363]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(y_train, train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "print(confusion_matrix_train)\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy, True Positive Rate and True Negative Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Specificity:  0.9456916374198233\n",
      "Train Recall:  0.7288356342797604\n",
      "Train Precision:  0.7571370585847652\n",
      "Train Accuracy:  0.9048121777559538\n"
     ]
    }
   ],
   "source": [
    "# Metrics on train data for ann_model 1\n",
    "#Accuracy\n",
    "accuracy_Train_M1 = (confusion_matrix_train[0,0]+confusion_matrix_train[1,1])/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1]+confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Train_M1 = confusion_matrix_train[0,0]/(confusion_matrix_train[0,0]+confusion_matrix_train[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Train_M1 = confusion_matrix_train[1,1]/(confusion_matrix_train[1,0]+confusion_matrix_train[1,1])\n",
    "#precision\n",
    "precision_Train_M1 = confusion_matrix_train[1,1]/(confusion_matrix_train[0,1]+confusion_matrix_train[1,1])\n",
    "\n",
    "print(\"Train Specificity: \",specificity_Train_M1)\n",
    "print(\"Train Recall: \",recall_Train_M1)\n",
    "print(\"Train Precision: \",precision_Train_M1)\n",
    "print(\"Train Accuracy: \",accuracy_Train_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Specificity:  0.9409106953759265\n",
      "Test Recall:  0.718018839258584\n",
      "Test Precision:  0.7384375\n",
      "Test Accuracy:  0.8988886342804766\n"
     ]
    }
   ],
   "source": [
    "# Metrics on test data\n",
    "#Accuracy\n",
    "accuracy_Test_M1 = (confusion_matrix_test[0,0]+confusion_matrix_test[1,1])/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1]+confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#specificity or true negative rate (TNR)\n",
    "specificity_Test_M1 = confusion_matrix_test[0,0]/(confusion_matrix_test[0,0]+confusion_matrix_test[0,1])\n",
    "#sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "recall_Test_M1 = confusion_matrix_test[1,1]/(confusion_matrix_test[1,0]+confusion_matrix_test[1,1])\n",
    "#precision\n",
    "precision_Test_M1 = confusion_matrix_test[1,1]/(confusion_matrix_test[0,1]+confusion_matrix_test[1,1])\n",
    "\n",
    "print(\"Test Specificity: \",specificity_Test_M1)\n",
    "print(\"Test Recall: \",recall_Test_M1)\n",
    "print(\"Test Precision: \",precision_Test_M1)\n",
    "print(\"Test Accuracy: \",accuracy_Test_M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('Accuracy Plot')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XVW9///XJyc5mdM0Q6ekcwulLZ0IBS/zoAIiRUWgX1DBAeHK1e/l6le8znzlXq7XH6I/uSoq4ABUlIsyoyJyQQU6UAqllJbSIR3TtEnTZjwnn+8feyc9TZM008n4fj44j7P32nuvs3bPg/PJWmuvtczdERER6amUgS6AiIgMbQokIiLSKwokIiLSKwokIiLSKwokIiLSKwokIiLSKwokIkOAmU0ys4NmFunnz91sZuf352fK0KNAIkPGQP2omdk1ZhYPf8hbXj9I8mceca/uvtXdc9w9noTPcjM7FN7XdjO7vbsBy8zONrPyvi6bDA2pA10AkSHi7+5++kAXIonmu/tGM5sF/AV4C/jRwBZJhgrVSGRYMLNPmdlGM9tnZo+Y2YQw3czsu2a2x8yqzWyNmc0Nj11kZm+YWU34l/jne/C5fzGzTybsX2NmLyTsu5ldb2YbzGy/md1pZtam3OvCMrxhZovM7JfAJODRsJbwf8xsSphXanjdhPA+94X3/amEPL9hZg+a2S/CfNeaWVlX7sfd3wSeB+a2c6/pZnaHme0IX3eEadnAk8CEhBrbhO7+W8rQpUAiQ56ZnQv8O3A5MB7YAiwLD78HOBM4DsgHrgAqw2M/Az7t7rkEP5x/TlIRLwZOBuaHZXxvWO4PA98APgrkAZcAle7+EWAr8P6wOevb7eT5AFAOTAAuA/7NzM5LOH4Jwb9BPvAI0KWmODObDZwBvNLO4S8DpwILwntZDHzF3Q8BFwI7wvLmuPuOrnyeDA8KJDIcXAXc7e6r3L0B+BLwLjObAjQBucAswNx9nbvvDK9rAmabWZ6773f3VZ18xqlmVpXwOrUb5bvN3avcfSvwLMEPMcAngW+7+3IPbHT3LcfKzMwmAqcDX3T3endfDfwU+EjCaS+4+xNhn8ovCX74O7PKzPYDj4Z53dPOOVcBt7j7HnevAL7Z5jNlhFIgkeFgAkEtBAB3P0hQ6yhx9z8T/DV+J7DbzO4ys7zw1A8BFwFbzOw5M3tXJ5/xorvnJ7xe7Eb5diVs1wI54fZE4O1u5NNiArDP3WsS0rYAJZ18ZkZLs1gHFrn7aHef7u5fcffmDj43MdBtCdNkhFMgkeFgBzC5ZSdssy8EtgO4+/fd/SRgDkET1xfC9OXuvgQYA/wOeLAHn30IyErYH9eNa7cB0zs41tm03DuAAjPLTUibRHi/SXTEv3P4mS1NWJpGfARTIJGhJs3MMhJeqcD9wLVmtsDM0oF/A15y981mdrKZnWJmaQQ/+vVA3MyiZnaVmY1y9ybgANCTR2tXAx80sywzmwF8ohvX/hT4vJmdFD4UMMPMWn6odwPT2rvI3bcBfwP+Pfw3mBd+7n09KH93PAB8xcyKzawI+Brwq4TyFprZqCSXQQYhBRIZap4A6hJe33D3Z4CvAg8BOwn+yr8yPD8P+Amwn6ApphL4TnjsI8BmMzsAXA9c3YPyfBdoJPgh/Tnd+DF3998AtxIEwhqCWlFBePjfCX60qzp4mmwpMIWgRvAw8HV3/2MPyt8d3wJWAGuA14BVYVrL014PAJvCMqvJawQxLWwlIiK9oRqJiIj0igKJiIj0igKJiIj0igKJiIj0yoiYtLGoqMinTJky0MUQERlSVq5cudfdi4913ogIJFOmTGHFihUDXQwRkSHFzI45ZQ+oaUtERHpJgURERHpFgURERHplRPSRiMjw0NTURHl5OfX19QNdlGElIyOD0tJS0tLSenS9AomIDBnl5eXk5uYyZcoUEhaalF5wdyorKykvL2fq1Kk9ykNNWyIyZNTX11NYWKgg0ofMjMLCwl7V8hRIRGRIURDpe739N1Ug6cTDr5Tzqxe79Bi1iMiIpUDSicfX7FIgEZFWlZWVLFiwgAULFjBu3DhKSkpa9xsbG7uUx7XXXsv69euTXNL+pc72ThRmR3m1vGqgiyEig0RhYSGrV68G4Bvf+AY5OTl8/vNHrjvm7rg7KSnt/51+zz33JL2c/U01kk4U5kTZf6gRLf4lIp3ZuHEjc+fO5frrr2fRokXs3LmT6667jrKyMubMmcMtt9zSeu7pp5/O6tWricVi5Ofnc/PNNzN//nze9a53sWfPngG8i55TjaQTBdlRYs3OgboYo7J69ny1iCTHNx9dyxs7DvRpnrMn5PH198/p0bVvvPEG99xzDz/60Y8AuO222ygoKCAWi3HOOedw2WWXMXv27COuqa6u5qyzzuK2227jpptu4u677+bmm2/u9X30N9VIOlGYEwWg8lDDAJdERAa76dOnc/LJJ7fuP/DAAyxatIhFixaxbt063njjjaOuyczM5MILLwTgpJNOYvPmzf1V3D6lGkknCrLTAag81Mi0Y06kLCL9qac1h2TJzs5u3d6wYQPf+973ePnll8nPz+fqq69ud5xGNBpt3Y5EIsRisX4pa19TjaQThdlhjeRg157GEBEBOHDgALm5ueTl5bFz506efvrpgS5SUqlG0omWpq19hxRIRKTrFi1axOzZs5k7dy7Tpk3jtNNOG+giJZWNhCeSysrKvCcLWzXE4hz/laf4/HuO48ZzZyahZCLSHevWreOEE04Y6GIMS+3925rZSncvO9a1atrqRHpqhJz0VCpVIxER6ZACyTEUZEfVRyIi0omkBhIzu8DM1pvZRjPr8OFoM7vMzNzMyhLSvhRet97M3tvdPPtKQXZUfSQiIp1IWiAxswhwJ3AhMBtYamaz2zkvF/gs8FJC2mzgSmAOcAHwX2YW6WqefakoJ6qmLRGRTiSzRrIY2Ojum9y9EVgGLGnnvP8LfBtIfMh6CbDM3Rvc/R1gY5hfV/PsM0GNRAMSRUQ6ksxAUgJsS9gvD9NamdlCYKK7P9bFa4+ZZ0Le15nZCjNbUVFR0bM7IBiUuE/zbYmIdCiZgaS9lVJaf43NLAX4LvAv3bi20zyPSHS/y93L3L2suLjnw9ILs6M0xZ0D9UNzxKmI9J2zzz77qMGFd9xxB//4j//Y4TU5OTkA7Nixg8suu6zDfI81ROGOO+6gtra2df+iiy6iqmpwzE6ezEBSDkxM2C8FdiTs5wJzgb+Y2WbgVOCRsMO9o2uPlWefK8jWoEQRCSxdupRly5YdkbZs2TKWLl16zGsnTJjAb3/72x5/dttA8sQTT5Cfn9/j/PpSMgPJcmCmmU01syhB5/kjLQfdvdrdi9x9irtPAV4ELnH3FeF5V5pZuplNBWYCLx8rz2Q4PLpd/SQiI91ll13GY489RkND8HuwefNmduzYwYIFCzjvvPNYtGgRJ554Ir///e+Punbz5s3MnTsXgLq6Oq688krmzZvHFVdcQV1dXet5N9xwQ+v081//+tcB+P73v8+OHTs455xzOOeccwCYMmUKe/fuBeD2229n7ty5zJ07lzvuuKP180444QQ+9alPMWfOHN7znvcc8Tl9KWlTpLh7zMxuBJ4GIsDd7r7WzG4BVrh7hwEgPO9B4A0gBnzG3eMA7eWZrHsAKGyZuFFjSUQGlydvhl2v9W2e406EC2/r8HBhYSGLFy/mqaeeYsmSJSxbtowrrriCzMxMHn74YfLy8ti7dy+nnnoql1xySYdrof/whz8kKyuLNWvWsGbNGhYtWtR67NZbb6WgoIB4PM55553HmjVr+OxnP8vtt9/Os88+S1FR0RF5rVy5knvuuYeXXnoJd+eUU07hrLPOYvTo0WzYsIEHHniAn/zkJ1x++eU89NBDXH311X3zb5UgqeNI3P0Jdz/O3ae7+61h2tfaCyLufnZYG2nZvzW87nh3f7KzPJOpQPNtiUiCxOatlmYtd+df//VfmTdvHueffz7bt29n9+7dHebxP//zP60/6PPmzWPevHmtxx588EEWLVrEwoULWbt2bbvTzyd64YUX+MAHPkB2djY5OTl88IMf5Pnnnwdg6tSpLFiwAEjuNPWatPEYWmcAViARGVw6qTkk06WXXspNN93EqlWrqKurY9GiRdx7771UVFSwcuVK0tLSmDJlSrvTxidqr7byzjvv8J3vfIfly5czevRorrnmmmPm09kTpenp6a3bkUgkaU1bmiLlGDLSImRHI2raEhEgeArr7LPP5uMf/3hrJ3t1dTVjxowhLS2NZ599li1btnSax5lnnsl9990HwOuvv86aNWuAYPr57OxsRo0axe7du3nyydbGGHJzc6mpqWk3r9/97nfU1tZy6NAhHn74Yc4444y+ut0uUY2kCwpyNChRRA5bunQpH/zgB1ubuK666ire//73U1ZWxoIFC5g1a1an199www1ce+21zJs3jwULFrB48WIA5s+fz8KFC5kzZ85R089fd911XHjhhYwfP55nn322NX3RokVcc801rXl88pOfZOHChf262qKmke+CJXf+lbyMVH75iVP6sFQi0l2aRj55NI18khVq4kYRkQ4pkHSBppIXEemYAkkXFOZENd+WyCCh/w/7Xm//TRVIuqAwO0pjvJmDDZpvS2QgZWRkUFlZqWDSh9ydyspKMjIyepyHntrqgoJwdPu+Q43kZqQNcGlERq7S0lLKy8vpzYzecrSMjAxKS0t7fL0CSRckDkqcXJg9wKURGbnS0tKYOnXqQBdD2lDTVhe0zACsDncRkaMpkHSBZgAWEemYAkkXtM4ArLEkIiJHUSDpgsxohMy0CPvUtCUichQFki4q0Oh2EZF2KZB0UVFOlL0KJCIiR1Eg6aKgRqLOdhGRtpIaSMzsAjNbb2Ybzezmdo5fb2avmdlqM3vBzGaH6VeFaS2vZjNbEB77S5hny7ExybyHFgXZ6eojERFpR9IGJJpZBLgTeDdQDiw3s0fcPXHdyPvd/Ufh+ZcAtwMXuPt9wH1h+onA7919dcJ1VyUuy9sfCnOiVIbzbXW0DrOIyEiUzBrJYmCju29y90ZgGbAk8QR3P5Cwmw20N4HOUuCBpJWyiwqyozTEmjnUGB/oooiIDCrJnCKlBNiWsF8OHLUylJl9BrgJiALntpPPFbQJQMA9ZhYHHgK+5f0wg1vLNCn7DjaSk66ZZUREWiSzRtJe+89RP/jufqe7Twe+CHzliAzMTgFq3f31hOSr3P1E4Izw9ZF2P9zsOjNbYWYr+mKCt5bR7ZXqcBcROUIyA0k5MDFhvxTY0cn5y4BL26RdSZtmLXffHr7XAPcTNKEdxd3vcvcydy8rLi7uZtGPljgDsIiIHJbMQLIcmGlmU80sShAUHkk8wcxmJuy+D9iQcCwF+DBBgGlJSzWzonA7DbgYSKytJE3iDMAiInJY0hr73T1mZjcCTwMR4G53X2tmtwAr3P0R4EYzOx9oAvYDH0vI4kyg3N03JaSlA0+HQSQC/An4SbLuIZFmABYRaV9Se43d/QngiTZpX0vY/lwn1/4FOLVN2iHgpL4tZddkRSNkpKVoUKKISBsa2d5FZkZhdrqatkRE2lAg6QZN3CgicjQFkm5QIBEROZoCSTcU5kTV2S4i0oYCSTcUZkc1IFFEpA0Fkm4oyE6nvqmZ2sbYQBdFRGTQUCDphkKNJREROYoCSTe0DEpUh7uIyGEKJN2giRtFRI6mQNINheHEjWraEhE5TIGkGwpy1LQlItKWAkk3ZEcjRFNTFEhERBIokHRDMN9WVPNtiYgkUCDppmB0uzrbRURaKJB0U0F2upq2REQSKJB0k5q2RESOpEDSTZoBWETkSAok3VSQHaW2MU5dY3ygiyIiMigkNZCY2QVmtt7MNprZze0cv97MXjOz1Wb2gpnNDtOnmFldmL7azH6UcM1J4TUbzez7ZmbJvIe2ijS6XUTkCEkLJGYWAe4ELgRmA0tbAkWC+939RHdfAHwbuD3h2NvuviB8XZ+Q/kPgOmBm+LogWffQnoJwdLuat0REAsmskSwGNrr7JndvBJYBSxJPcPcDCbvZgHeWoZmNB/Lc/e/u7sAvgEv7ttida5m4UR3uIiKBZAaSEmBbwn55mHYEM/uMmb1NUCP5bMKhqWb2ipk9Z2ZnJORZfqw8w3yvM7MVZraioqKiN/dxhJap5Pdpvi0RESC5gaS9voujahzufqe7Twe+CHwlTN4JTHL3hcBNwP1mltfVPMN873L3MncvKy4u7tENtKdQ822JiBwhmYGkHJiYsF8K7Ojk/GWEzVTu3uDuleH2SuBt4Lgwz9Ju5NnnctJTiUZS2KvOdhERILmBZDkw08ymmlkUuBJ4JPEEM5uZsPs+YEOYXhx21mNm0wg61Te5+06gxsxODZ/W+ijw+yTew1HMLBhLoqYtEREAUpOVsbvHzOxG4GkgAtzt7mvN7BZghbs/AtxoZucDTcB+4GPh5WcCt5hZDIgD17v7vvDYDcC9QCbwZPjqVxqUKCJyWNICCYC7PwE80Sbtawnbn+vguoeAhzo4tgKY24fF7LbCHE2TIiLSQiPbe6BQNRIRkVYKJD1QkJ2uqeRFREIKJD1QmBPlUGOc+ibNtyUiokDSAy2j29W8JSKiQNIjCiQiIocpkPRAywzAe9VPIiKiQNITmgFYROQwBZIeUNOWiMhhCiQ9kJeRSlrENChRRAQFkh7RfFsiIocpkPRQQXa6ltsVEUGBpMcKszXflogIKJD0mGYAFhEJKJD0kPpIREQCCiQ9VJQTpaYhRkNM822JyMimQNJDGpQoIhJQIOmhlkGJlWreEpERToGkhwpzNLpdRAS6GEjMbLqZpYfbZ5vZZ80svwvXXWBm681so5nd3M7x683sNTNbbWYvmNnsMP3dZrYyPLbSzM5NuOYvYZ6rw9eYrt9uDzQ3t5usaVJERAJdrZE8BMTNbAbwM2AqcH9nF5hZBLgTuBCYDSxtCRQJ7nf3E919AfBt4PYwfS/wfnc/EfgY8Ms2113l7gvC154u3kP3/fYTcN+H2j1UFPaRaCyJiIx0XQ0kze4eAz4A3OHu/wyMP8Y1i4GN7r7J3RuBZcCSxBPc/UDCbjbgYfor7r4jTF8LZLTUiPpVZj5sWw7NRz+ZlZeZSmqKacldERnxuhpImsxsKUHt4LEwLe0Y15QA2xL2y8O0I5jZZ8zsbYIayWfbyedDwCvunviLfU/YrPVVM7P2PtzMrjOzFWa2oqKi4hhF7egOyqCxBva+1V7+jNagRBGRLgeSa4F3Abe6+ztmNhX41TGuae8H3o9KcL/T3acDXwS+ckQGZnOA/wA+nZB8VdjkdUb4+kh7H+7ud7l7mbuXFRcXH6OoHSgtC97LV7R7WNOkiIh0MZC4+xvu/ll3f8DMRgO57n7bMS4rByYm7JcCOzo4F4Kmr0tbdsysFHgY+Ki7v51Qlu3hew1BP83irtxDjxRMh4xRUL683cOFOaqRiIh09amtv5hZnpkVAK8SNC3dfozLlgMzzWyqmUWBK4FH2uQ7M2H3fcCGMD0feBz4krv/NeH8VDMrCrfTgIuB17tyDz2SkgIlJ8H2le0eLshOVyARkRGvq01bo8KO8Q8C97j7ScD5nV0Qds7fCDwNrAMedPe1ZnaLmV0Snnajma01s9XATQR9MITXzQC+2uYx33TgaTNbA6wGtgM/6fLd9kTpybDnDWg4eNShwuyo1m0XkREvtavnmdl44HLgy13N3N2fAJ5ok/a1hO3PdXDdt4BvdZDtSV39/D5RUgbeDDtXw5TTjzhUkB2lpj5GY6yZaKrGdorIyNTVX79bCGoWb7v7cjObRtgMNeyVhHGrnX6SlkGJ+2vVvCUiI1eXaiTu/hvgNwn7mwgeyx3+sgth9NR2n9wqyjk839bYvIz+LpmIyKDQ1c72UjN72Mz2mNluM3sofKpqZCg9ud0Od80ALCLS9aatewieuJpAMKjw0TBtZCgtg5qdUL39iOTWGYC1druIjGBdDSTF7n6Pu8fC171AD0f5DUElLQMTj+wnKdRU8iIiXQ4ke83sajOLhK+rgcpkFmxQGTcXIlHYfmQ/yajMNCIppqYtERnRuhpIPk7w6O8uYCdwGcG0KSNDajqMnw/lR/aTpKQYo7M0TYqIjGxdnSJlq7tf4u7F7j7G3S8lGJw4cpSUwY5XIB47IrkwO8o+9ZGIyAjWm1F0N/VZKYaC0jKI1cGetUckF2RH1UciIiNabwJJu9O3D1utAxOP7Ccp0MSNIjLC9SaQHDUl/LA2egpkFR01nqRIU8mLyAjX6ch2M6uh/YBhQGZSSjRYmQXNW21rJNnpVNc10RRvJi2i+bZEZOTp9JfP3XPdPa+dV667d3XCx+GjpAz2roe6qtakghzNtyUiI5v+hO6O0rCfZMeq1iQNShSRkU6BpDsmLAreE8aTtEyTog53ERmpFEi6IzMfio4/YoR76wzACiQiMkIpkHRXaVkw55YHzyC0zgCslRJFZIRKaiAxswvMbL2ZbTSzm9s5fr2ZvRYupfuCmc1OOPal8Lr1ZvberuaZdCUnQW0l7N8MQH5mGimmGomIjFxJCyRmFgHuBC4EZgNLEwNF6H53P9HdFwDfBm4Pr50NXAnMAS4A/qtlwsgu5JlcpeFMwOF4Es23JSIjXTJrJIuBje6+yd0bgWXAksQT3P1Awm42h8esLAGWuXuDu78DbAzzO2aeSTdmDqRmHjGepCA7yj49tSUiI1Qyx4KUANsS9suBU9qeZGafIZi3Kwqcm3Dti22uLQm3j5lnmO91wHUAkyZN6n7pOxJJhQkLj1ibpFDTpIjICJbMGkl7c3EdNUre3e909+nAF4GvHOPaLuUZ5nuXu5e5e1lxcR+vwVV6EuxaA7Ggg70wO12rJIrIiJXMQFIOTEzYLwV2dHL+MuDSY1zb3TyTo6QM4o2w63UgnAFYNRIRGaGSGUiWAzPNbKqZRQk6zx9JPMHMZibsvg/YEG4/AlxpZulmNhWYCbzclTz7RenJwXs4nqQgO0pVbROxeHO/F0VEZKAlLZC4ewy4EXgaWAc86O5rzewWM7skPO1GM1trZqsJ+kk+Fl67FngQeAN4CviMu8c7yjNZ99ChUSWQO761n6Swdb6tpn4viojIQEvqxIvu/gTwRJu0ryVsf66Ta28Fbu1KngOi5KTWJ7cKWwYlHmqkODd9IEslItLvNLK9p0rLYP87cKiydb6tvRrdLiIjkAJJT5UcHpg4a1wukRTjhY17B7ZMIiIDQIGkpyYsBEuB8uWMzo5y2owiHn11B+4ja+FIEREFkp5Kz4Exs1uf3Lp43njK99fxann1ABdMRKR/KZD0RslJwZxbzc28d8440iLGY6/2/7AWEZGBpEDSG6VlUF8NlRsZlZnGWccV8/hrO2luVvOWiIwcCiS90WZg4sXzJrCzup6VW/cPYKFERPqXAklvFB0H0dzW8STnzx5LemqKmrdEZERRIOmNlAiULGytkeSkp3LurDE88fou4mreEpERQoGkt0rKgskbG2uBoHmroqaBl96pHOCCiYj0DwWS3io9GTwOO18F4NxZY8iKRnj01Z0DXDARkf6hQNJbrUvvBs1bmdEI558wlqde30mTZgMWkRFAgaS3csbAqElHLL178bzx7K9t4m9vq3lLRIY/BZK+UHrSEYHkrOOLyU1P5VE9vSUiI4ACSV8oPRkOlEPNLgDSUyO8e85Ynl67i4ZYfIALJyKSXAokfWHiKcH7G4cXa3z//AnU1Md4/i3NCCwiw5sCSV8oOQkmnwbP/QfUHwDg9BlF5Gel8dgaNW+JyPCmQNIXzOA9/xdq98JfvwdAWiSFC+aM449v7Ka+Sc1bIjJ8JTWQmNkFZrbezDaa2c3tHL/JzN4wszVm9oyZTQ7TzzGz1QmvejO7NDx2r5m9k3BsQTLvoctKToK5l8HffwDV24FgcOKhxjjPvrlngAsnIpI8SQskZhYB7gQuBGYDS81sdpvTXgHK3H0e8Fvg2wDu/qy7L3D3BcC5QC3wh4TrvtBy3N1XJ+seuu28r4E3w5+/BcCp0wooyony2BoNThSR4SuZNZLFwEZ33+TujcAyYEniCWHAqA13XwRK28nnMuDJhPMGr9GT4ZTr4dUHYOcaUiMpXDh3PM+8uZtDDbGBLp2ISFIkM5CUANsS9svDtI58AniynfQrgQfapN0aNod918zS28vMzK4zsxVmtqKioqI75e6dM/4FMvPhD18Bdy6eN576pmb+tG53/5VBRKQfJTOQWDtp7U6Ja2ZXA2XAf7ZJHw+cCDydkPwlYBZwMlAAfLG9PN39Lncvc/ey4uLi7pe+pzLz4awvwjvPwcY/cfKUAsbmpat5S0SGrWQGknJgYsJ+KXDUs7Bmdj7wZeASd29oc/hy4GF3b2pJcPedHmgA7iFoQhtcyj4Bo6fCH75Kisd534kTeG59BQfqm459rYjIEJPMQLIcmGlmU80sStBE9UjiCWa2EPgxQRBp79GmpbRp1gprKZiZAZcCryeh7L2TGoV3fxMq1sHq+7h4/nga4838Ya2at0Rk+ElaIHH3GHAjQbPUOuBBd19rZreY2SXhaf8J5AC/CR/lbQ00ZjaFoEbzXJus7zOz14DXgCLgW8m6h1454ZJgxPuz/8bCsamU5GdqcKKIDEupyczc3Z8AnmiT9rWE7fM7uXYz7XTOu/u5fVjE5DGD93wLfvZu7O93cvH8Jfzs+XfYf6iR0dnRgS6diEif0cj2ZJq4GGZfCn/9Hh+YESHW7Dy9dtdAl0pEpE8pkCTb+V+HeBPHr/sBUwqzeFTNWyIyzCiQJFvBNFj8KeyVX3LNjDr+/nYlFTVtH04TERm6FEj6w5lfgPRcLtt3F80OT72uMSUiMnwokPSHrAI48wvkbHuWyws28qsXt2pGYBEZNhRI+svi6yB/El+N3s+G3dV89Xev497uQH8RkSFFgaS/pKbDeV8nt+pN/mvuW/xmZTn3vbR1oEslItJrCiT9ae6HoKSM9275Dv8y8U2++ehaVm7ZP9ClEhHpFQWS/mQGSx/Axs7hnypu4fNZj/OPv1rBnpr6gS6ZiEiPKZD0t5wx8LHHYO5lfLrpV3yp4Xt1TE6qAAAYgElEQVT871+9RFO8eaBLJiLSIwokAyEtAz70Uzjny1ya8jw37fw8d/z+rwNdKhGRHlEgGShmcNb/gQ/fy/zIFq5cfS3PPPeXgS6ViEi3KZAMtDkfwD7+JNmpcU7585VsefHhgS6RiEi3KJAMAqkTT8I/+We2p4yj9KmPU/fc90FjTERkiFAgGSQKJ0yl/urH+VNzGZnPfpXmRz8HscaBLpaIyDEpkAwi86eXUHnRT/hBbAkpq34Ov/ogVL490MUSEemUAskgs/SUyWxb8Hn+ufEG4ltfhh+UwW8/AbvfGOiiiYi0S4FkkDEzvrlkDm9PuJjz4t9n83Efh7eegh++Cx74X1C+cqCLKCJyhKQGEjO7wMzWm9lGM7u5neM3mdkbZrbGzJ4xs8kJx+LhOu5t13KfamYvmdkGM/u1mQ27dWsz0iL86OqTSBs1nrNfPZd/GvsLqk6+Cbb8FX56LvxiCbzzvDrkRWRQSFogMbMIcCdwITAbWGpms9uc9gpQ5u7zgN8C3044VufuC8LXJQnp/wF8191nAvuBTyTrHgbShPxMnvjcGXz5ohP485YmFv9tMd+f/zBN534jaOb6+cVw93vhracVUERkQCWzRrIY2Ojum9y9EVgGLEk8wd2fdffacPdFoLSzDM3MgHMJgg7Az4FL+7TUg0haJIVPnTmNP3/+bC48cRy3P7eTs/82nz+854/4Rd+BAzvg/svhx2fA6vuhdt9AF1lERqBkBpISYFvCfnmY1pFPAE8m7GeY2Qoze9HMWoJFIVDl7rFj5Wlm14XXr6ioqOjZHQwSY/My+N6VC/n1daeSm5HKdQ+s5aOvzWPT0udhyX9BUz387gb4zxnw8/fDS3dB9fbuf5A77N0IK38O//1pePzzsGdd39+QiAwrlqzFlczsw8B73f2T4f5HgMXu/k/tnHs1cCNwlrs3hGkT3H2HmU0D/gycBxwA/u7uM8JzJgJPuPuJnZWlrKzMV6xY0Yd3N3Bi8WZ+8fctfPePb1Efi/PJM6bxT+dMI2vva7DuMXjzcdi7Pjh5wkKYdXHwKj4+mJYlUXMzVLwZ9L1s+Sts+Rsc3B0cyy6GhhqI1cPUs+DUG2DmeyFFz2eIjBRmttLdy455XhIDybuAb7j7e8P9LwG4+7+3Oe984P8nCCJ7OsjrXuAx4CGgAhjn7rG2n9GR4RRIWuypqec/nlzPQ6vKGT8qg38+/zgunj+erGgq7N0Abz4WBJbt4X0XzoBZ74OpZ0LFW4cDR13YHJZXApNPg8n/AFNOD86v3Qer7oWXfwo1O2D01GClx4VXQ0begN27iPSPwRBIUoG3CGoS24HlwP9y97UJ5ywk6O+4wN03JKSPBmrdvcHMioC/A0vc/Q0z+w3wkLsvM7MfAWvc/b86K8twDCQtVmzex9cfWcvaHQfISU/l/fPH8+GyiSycmI+ZwYGdsP7xIKhsfh6aw1bB0VPCwHEaTDkN8icfXWNpEW+CdY/CSz+CbS9BNAcWXBUElaIZ/XavItK/BjyQhIW4CLgDiAB3u/utZnYLsMLdHzGzPwEnAjvDS7a6+yVm9g/Aj4Fmgn6cO9z9Z2Ge0wg67gsInvq6uqU5rCPDOZAAuDsvv7OP36ws5/E1O6lrijNjTA6Xl5XygYWlFOemByfWVcH2lVA8C0Z11l3Vie2r4KUfw+sPQXMTzHwPLP40TDsbIql9dUsiMggMikAyWAz3QJLoYEOMx9fs4MEV5azcsp9IinHurDFcXjaRs48vJi3SR30cNbthxd2w4mdwqAIyC+C4C4Lms+nnQjSrbz5HRAaMAkmCkRRIEm3cc5DfrNzGQyu3s/dgA0U56Xxg4QROm1HEwomjGZWV1vsPiTXA+ieDTv4NT0N9NaRmwLRzgqBy3AWQU3zsfJrjsH9z0L+z9y2o2QXTzwny6e+aTmP4RLqCoYxwCiQJRmogadEUb+a59RU8uGIbf35zD7Hm4DufVpzNokmjWTgpn0WTRnPc2FwiKR30k3RFvCnowH/zcVj/BFRvAwwmngKzLgqeHssZC5UbDgeMvW8F25UbIZ4w23EkGuxnj4F5l8P8K2Fcpw/n9d6BnfDinbDiXvA4zPkALPwITDq14/4jkWFMgSTBSA8kiQ42xFhTXsUrW6t4Zet+Vm2tYt+h4Ac8Oxph/sR8Fk7KZ+HE0SyYlE9RTnrPPsgddr0WBpXHg+22LBJ0+hcfD0Uzoei44FU4A6LZsOEP8OqyYPR+cxOMnRsElBM/DLnjev6P0NbeDfDX7wWf5XGY88Hg819/CBoPQuFMWPQRmL8Ucsb03eeKDHIKJAkUSDrm7mzdV8uqrft5ZWsVq7buZ93OGuJhraUkP5MTS0ZxYuko5pfmc2LJqJ41iVVthfVPQcOBwwGjYCqkdiFQ1e4LftRfXRY8zmwpQT/M/KVw/EU9b4IqXwEvfDcIdqnpQe3jH24MghtA4yFY+ztY9QvY9iKkpAZNdYs+CtPP08MFMuwpkCRQIOmeusY4a8qrWFNezZrt1awpr2JLZW3r8cmFWcwrzWdeGGBOGJ9HJMVojDUffsXbvMeaaYzHGZObwezxeaT0tAlt74YgoKz5ddB0Fs2FqWdAwbTgVTg9eM8rgZTI0de7w8Y/wQt3wJYXICMfFn8qePKss76cirfglV/Cqw8EDxfkjg8egZ5/ZVA7Ss1UYJFhR4EkgQJJ71XXNvHa9mrWbK/itfJq1pRXs72qrkd5FeWkc+ZxRZx1XDFnzCymILsHEzg3N8PWvwU/7OUrYf87wSj8FpFoULMomAYF04PaTyQtGFy5+zXInRDUPhZ9FNJzu/658aZgWv9VvwgCkjcfPmaR4EGD1PRO3sNXpCUtGm4nvjIhuyiYXSBnTNBPlFXQfmAUSSIFkgQKJMmx92ADr22vZsPuGgwjLWJEUyNEU1OCV8TC9yAtLWJsqjjEc29V8PyGCvbXNmEG80rzOeu4Ys46rpj5paNI7ckjys3NULMT9m2CfW+H75tg3zvBe1NYoyo6Hk77XNDPktrLFQiqtwdPqjUcDJ5ei9WHr8TtcL+pLnh4INYQvOINwVLKsfrD6fFOhkNZCmQVBQ8r5BQHwSWnGLIKg1pV5mjIzA+3w/f0vPantIk1Qt3+YFaDuv1B02HdvvB9fxDM8ifBqImQPxHySnv/byX9r64Ktr0MM87v8dRGCiQJFEgGn3iz89r2ap5bX8Fzb+1h9bYqmh1GZaZx+swiTptexLhR6eRmpJGbkUpe+J4dTe1+s5h78Dhx7V4YM2fwzhfmHgSVplo4tBcO7oFDe+BgRTAHWst24ntiLawtSwmCSeboYDaChmqo3Q+NNR1fk5IWzn6Q+LtgQVNe/sQwuEwKtycFNaacsUENSjWmgXWo8vDUR1v+Gj7g4nDD32DsnB5lqUCSQIFk8KuqbeSFjXvDwFLBnpr2/zo3g9z01MMBJjONiaOzOHnKaMqmjGZ6cU4wNcxI4B4EnbqqoCZRXxVst7wnpjUegoxRQVDJKkh4b7MdzQ6a7w5sD/qgqrYFD0pUh+9VW4NjLVPttLCUoHaUMzYhuBSH+2ODudkiaUGTYyTa8XZqehD0Rsp32Bs1u2DzC4cDR8WbQXpqJkw8+fAUSKUnQ1pGjz5CgSSBAsnQ4u5sqaxlf20jNfUxDtQ3UVMfo6a+iQN1wXtL+oG6GBsrDrY+wpyflUbZ5NGcNLmAk6eMZm7JKDLS+v8vZXentjHOwYYYBxtiHGqI0RTv2v9rKQZ5mWnkZ6YxKjOtZ019ydQcD37EqrcFtaaDuxNqTy37YS2qs+a6jkTSgyCUXXS4j6i97cyCoH8rmj08A09zc/Bgx4HtwdpDB7aHAX477FgVNNlCEHgnnRpMuDr59GDW7z5qiuxqINFjJjLomBlTirKZQnaXznd3Nu09xMrN+1m+eR8rt+znT+uCiaSjkRROLB1F2ZTRzC/NJ8WMhlichqZm6sP3hlic+vC9IdZMfVOcWNzxMO9mDxp6mj3YaHYn2HTizc6hhjiHGg8HjJb9vvobLTc9lVFZaYzOipKfFQSX/Kw08jOjjM1LZ1JhNpMLsigZndl3U+B0JiUSzNV2rPna3IPHvWt2B+Nx4k1B090Rr6Yjt1ua9Q7tDQPTbtj1evCD2tzU/udYJAgo6XlBzaf1PUxLzzlcnpaHI9yBcL9124OaVrwp+KzW8oXbzbHDZU1JDWbSnvU+GL+wd82ljYcO1yyqy8OgUR4MkG17z5Eo5E2A4hOg7ONBjWPcvAF/YlA1EhmW9h5sYOWW/azcEgSX17dXd1ojMIOM1AgZaSmkp0ZIjRhmkGKGEbwT/BektRwzIzsaITs9lZzwFWwHadkJadHUrv3YNDc7B+qbqKoNX3WN4XYjVXVNVNc2UVUX7Dcn3FIkxZiQn8HkgmwmFWYxuSCLyYVZTCrIZkJ+BrWN8db8DtQFeVfXBXlVt+bbSE56KsePy+OEcbkcPy6XyYXZvZvxoC+4B810ByuCoHJoT9h0dyBYN6fhQLgd7tdXH95uOBjkYSlhzcWCd0uh9UttSUtJC5vawua2lITtxPT6A1C+PBjAmjsejr8Qjn9f8Cj6scZGuQcLxr39TPDk35a/hcEpLQjOeaVBsMibAKNatkuCV3ZRv9a+1LSVQIFE6pvibNxzkBQz0tNSSE9NISMt0vqemmJDrm+ludmpONjAlspaNlceYmtlLVv21bK18hBb9tVSVdvBX/BtpKYY+Vlp5IVNadW1TbxTeai1RpWRlsJxY3OZNS73iABT2NNZD4aL2n3BrAvrH4eNf4amQ8G4phnnBTWVme8O+p8g6Kfa9JcgcGx8JljfB4KaxYzzgierJr2rx30ZyaJAkkCBREai6tomtuw7xJbKWnYfqCcnPZVRmWmMam0ei5KfmUZWNHJUEK1rjLNhTw1v7qzhzV01rN99gDd31lB56PB8aEU5UcbmZVCUk05xbvBq3c5Jpzg3SnFOBnmZqUMuSHdbUz2881w4JdCTQY0pJTXot4g1Hq69pI+CaWcFgWPGeUGNYxBTIEmgQCLSNypqGnhz1wHW76ph456D7KlpYO/BBirC9/aaD6ORFEZlpZGbnkpOxuEmwJyMVHJbmv/C7cxoKvHmZpriTlO8OXw5jbFgO9Z8eDs7PZVxeRmMH5XBuFEZjB+VSXFuer81wzU3O40JZWxqncUhRmTnKrI2PU3ulmdIiWYQPf7d2Mx3Q0lZv/Rn1DfFeXVbFS+9s4/rz5re5WbVttTZLiJ9Lqh5BDMStOXuVNc1UVHTQEUYXFq2D9QFT9odbIhxsD7G1kO1rU+01dTHWud260xaxEhNCQa2pkVSONgQoyHWfMQ5kRRjTG56GFgyGJcXBJeg6fLweRb2fbWkWZjWEItzsCHOwfoYBxuaONQQp6YhxsH6YDvxKbzYMct8eviCrF0Rjnszzgnj13HC+Fxmjcvj+HG5jMrsg6UcCALHK1ureHFTJS+9U8mqrVU0xpoxg3NnjWFuyag++ZyOqEYiIgPK3WmINVNTH6OuMU5qxEiNGNFICmmtr6P7sNydqtomdlbXs+tAXfBeXc+OqsP7O6vqqWuKd6s8ZpAdPVxryk4Paks5CTWqrGiE9NQIaalHlrNlBoeWtNSIsedAA+t2BU2D63YdOKLvqiQ/k1njcpk1PpeZY4LAkhU9/KBGdjRCVnoqWWmRIwbi1jfFWbVlPy++s48XN1WyelsQOFIMZk/I49SphZw6rZCTpxT0at2hQVEjMbMLgO8RLLX7U3e/rc3xm4BPAjGgAvi4u28xswXAD4E8IA7c6u6/Dq+5FzgLqA6zucbdVyfzPkQkecyMjLRIt8f7mBmjs6OMzo4ye0Jeu+e4O3VN8dYaT/BIN60D952WR7mDc9PTIkf9aPcld2d3QmB5M3x/7q2KY9ZwsqIRsqJBENtVXU9jPAgccyaM4mPvmsyp0wopm1LQZ7Wc7khaIDGzCHAn8G6gHFhuZo+4+xsJp70ClLl7rZndAHwbuAKoBT7q7hvMbAKw0syedveq8LovuPtvk1V2ERkezIys6OBpwTczxoV9Ouccf3htm4ZYnG37ajnYEA/HIsVaB7TWNgZjk2obYxwM38fmZXDqtALKphSQl9H/gaOtZP4LLwY2uvsmADNbBiwBWgOJuz+bcP6LwNVh+lsJ5+wwsz1AMVCFiMgwk54aYcaYbsxCPcgkcxhsCbAtYb88TOvIJ4An2yaa2WIgCrydkHyrma0xs++aWbsPs5vZdWa2wsxWVFRUdL/0IiLSJckMJO01MrbbCGhmVwNlwH+2SR8P/BK41r114YcvAbOAk4EC4Ivt5enud7l7mbuXFRd3smCRiIj0SjIDSTkwMWG/FNjR9iQzOx/4MnCJuzckpOcBjwNfcfcXW9LdfacHGoB7CJrQRERkgCQzkCwHZprZVDOLAlcCjySeYGYLgR8TBJE9CelR4GHgF+7+mzbXjA/fDbgUeD2J9yAiIseQtM52d4+Z2Y3A0wSP/97t7mvN7BZghbs/QtCUlQP8JnxGfKu7XwJcDpwJFJrZNWGWLY/53mdmxQRNZ6uB65N1DyIicmwakCgiIu3q6oDEQbZijoiIDDUKJCIi0isjomnLzCqALT28vAjY24fFGQyG2z3pfga/4XZPw+1+oP17muzuxxw/MSICSW+Y2YqutBEOJcPtnnQ/g99wu6fhdj/Qu3tS05aIiPSKAomIiPSKAsmx3TXQBUiC4XZPup/Bb7jd03C7H+jFPamPREREekU1EhER6RUFEhER6RUFkk6Y2QVmtt7MNprZzQNdnt4ys81m9pqZrTazITlnjJndbWZ7zOz1hLQCM/ujmW0I30cPZBm7o4P7+YaZbQ+/p9VmdtFAlrE7zGyimT1rZuvMbK2ZfS5MH8rfUUf3NCS/JzPLMLOXzezV8H6+GaZPNbOXwu/o1+HkuV3LU30k7QuXCn6LhKWCgaVtlgoeUsxsM8HSxkN2IJWZnQkcJJgZem6Y9m1gn7vfFgb80e7e7jo1g00H9/MN4KC7f2cgy9YT4ezc4919lZnlAisJZum+hqH7HXV0T5czBL+ncOb0bHc/aGZpwAvA54CbgP9292Vm9iPgVXf/YVfyVI2kY61LBbt7I9CyVLAMIHf/H2Bfm+QlwM/D7Z8T/E8+JHRwP0NWuF7QqnC7BlhHsDLqUP6OOrqnISlcz+lguJsWvhw4F/htmN6t70iBpGPdXSp4KHDgD2a20syuG+jC9KGx7r4Tgv/pgTEDXJ6+cGO4nPTdQ6kZKJGZTQEWAi8xTL6jNvcEQ/R7MrOIma0G9gB/JFjKvMrdY+Ep3fq9UyDpWJeXCh5CTnP3RcCFwGfCZhUZfH4ITAcWADuB/29gi9N9ZpYDPAT8b3c/MNDl6Qvt3NOQ/Z7cPe7uCwhWrl0MnNDeaV3NT4GkY11aKngocfcd4fseghUoh8syxbsTVs4cT/BX1pDl7rvD/9GbgZ8wxL6nsN39IeA+d//vMHlIf0ft3dNQ/54A3L0K+AtwKpBvZi2LHXbr906BpGPHXCp4KDGz7LCjEDPLBt7D8Fmm+BHgY+H2x4DfD2BZeq3lBzf0AYbQ9xR25P4MWOfutyccGrLfUUf3NFS/JzMrNrP8cDsTOJ+g3+dZ4LLwtG59R3pqqxPh43x3cHip4FsHuEg9ZmbTCGohECyxfP9QvB8zewA4m2DK693A14HfAQ8Ck4CtwIfdfUh0YHdwP2cTNJc4sBn4dEv/wmBnZqcDzwOvAc1h8r8S9CkM1e+oo3tayhD8nsxsHkFneoSgMvGgu98S/kYsAwqAV4Cr3b2hS3kqkIiISG+oaUtERHpFgURERHpFgURERHpFgURERHpFgURERHpFgUSkD5hZPGEW2NV9OVu0mU1JnB1YZLBJPfYpItIFdeGUEyIjjmokIkkUrgHzH+H6Dy+b2YwwfbKZPRNO+PeMmU0K08ea2cPhWhGvmtk/hFlFzOwn4foRfwhHJIsMCgokIn0js03T1hUJxw64+2LgBwQzJRBu/8Ld5wH3Ad8P078PPOfu84FFwNowfSZwp7vPAaqADyX5fkS6TCPbRfqAmR1095x20jcD57r7pnDiv13uXmhmewkWS2oK03e6e5GZVQCliVNThFOX/9HdZ4b7XwTS3P1byb8zkWNTjUQk+byD7Y7OaU/inEdx1L8pg4gCiUjyXZHw/vdw+28EM0oDXEWw3CnAM8AN0Lr4UF5/FVKkp/RXjUjfyAxXnGvxlLu3PAKcbmYvEfzhtjRM+yxwt5l9AagArg3TPwfcZWafIKh53ECwaJLIoKU+EpEkCvtIytx970CXRSRZ1LQlIiK9ohqJiIj0imokIiLSKwokIiLSKwokIiLSKwokIiLSKwokIiLSK/8PzThOlWRbn34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Loss Function Plot')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the above plots and analyze the Train and Validation curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Hidden Layers - Build your own Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Experiment with learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference Links:\n",
    "\n",
    "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "\n",
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
